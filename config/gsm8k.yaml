neptune:
  workspace: imbesat-rizvi
  project-name: GSM8k-NAN
  run-name: GSM8k-NAN
  tags:
    - word-problems
    - numeric-encoding

exp:
  name: numerical_reasoning
  
  data_args:
    dataset_path: allenai/lila
    name: GSM8k_structured
    split: # None i.e. by default all
    filter_kwargs: 
      col_filter: 
        output_answer: is_number
    transform_kwargs:
      col_transform: 
        output_answer: to_number
    resplit_kwargs:
      test_split: validation
      test_size: 0.1
      seed: 42
    tokenizer_model: bert-base-uncased
    tokenizer_wrapper: NANTokenizer
    text_col: input
    out_cols: &oc
      - output_answer
    prune_cols: true
    dataloader_kwargs:
      batch_size: 16
      shuffle: false # leave as false for comparison with prediction
      num_workers: 2

  neural_net_args:
    net: bert-base-uncased
    embedder: NANEmbedder
    embedder_kwargs:
      emb_net: fcn
      emb_kwargs:
        # prefer 1 layered linear projection to underlying model embedding size
        output_size: 768
        num_layers: 1
        dropout: 0.2 # immaterial for 1-layer linear net
        non_linearity: ReLU # immaterial for 1-layer linear net
      nums_kwargs:
        digit_kwargs: 
          int_decimals: 12
          frac_decimals: 7
          scale: true
        order_kwargs: 
          # scale_exp: 13
        sinusoidal_kwargs: 
          # scale_base: 10000
          # exp_divisor: 50
        dice_kwargs:
          # low: 0
          # high: 10000
          # dim: 10
        concat: true
      aux_kwargs:
        log_aux: true
        concat: true
      use_aux: false
      random_state: 42
    head_type: classifier
    output_sizes: 20 # immaterial for model_type regressor; 1 for sign, 12 int_decimals, 7 frac_decimals
    head_kwargs:
      num_layers: 3
      hidden_size: 256 # immaterial for 1-layer linear net
      dropout: 0.2 # immaterial for 1-layer linear net
      non_linearity: ReLU # immaterial for 1-layer linear net

  model_args:
    int_decimals: 12
    exp_ub: 12
    target_names: *oc
    optimizer_name: AdamW
    optimizer_kwargs:
      lr: 1.0e-5
    scheduler_name: ReduceLROnPlateau
    scheduler_kwargs:
      patience: 10
    scheduler_config:
      monitor: val_loss
      mode: min
      frequency: 1

  trainer_args:
    default_root_dir: outputs/nr/gsm8k
    max_epochs: 100
  
  trainer_callbacks:
    EarlyStopping:
      monitor: val_loss
      min_delta: 1.0e-6
      patience: 10
      mode: min

  result_args:
    predictions:
      target_cols: *oc
      save_path: outputs/nr/gsm8k/predictions_and_target.csv
    plot_args:
      save_path: outputs/nr/gsm8k